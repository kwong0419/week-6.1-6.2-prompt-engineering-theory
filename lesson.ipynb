{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 6.1 & 6.2: Prompt Engineering\n",
    "\n",
    "**Note:** In this lesson you will be given examples for creating prompts based on using data and pandas as well as non-data examples. You will be shown how to structure your prompts for both types of examples.\n",
    "\n",
    "## <ins>Setup</ins>  \n",
    "\n",
    "**Reminder:** Don't forget to setup your virtual environment, choose your python interpreter and install the ipykernel. If you do not remember how please refer to the [Python Workspace Setup Instructions](https://github.com/jdrichards-pursuit/python-virtual-environment-setup).\n",
    "\n",
    "### 1. Retrieving Your API Key\n",
    "\n",
    "Before we begin, you will need to retrieve your API key from Gemini.\n",
    "\n",
    "Use the following set of instructions to sign up for an account and retrieve your API key.\n",
    "\n",
    "[Gemini API Key](https://github.com/jdrichards-pursuit/gemini-api-key-acquire?tab=readme-ov-file)\n",
    "\n",
    "### 2. Setting Up Your Environment Variables\n",
    "\n",
    "Now that you have your API key, you can set up your environment variables.\n",
    "\n",
    "Create a new file called `.env` and add the following line of code:\n",
    "\n",
    "```bash\n",
    "API_KEY=<your-api-key>\n",
    "```\n",
    "\n",
    "### 3. Installing Required Libraries\n",
    "\n",
    "Now that you have your API key, you can install the required libraries.\n",
    "\n",
    "```bash\n",
    "pip install python-dotenv\n",
    "```\n",
    "\n",
    "### 4. Importing Required Libraries\n",
    "\n",
    "Now that you have your API key, you can import the required libraries. When you run this code, it will print your API key to the console.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "print(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After viewing your API key, you may now want to remove the print statement for security reasons.\n",
    "\n",
    "### 5. Importing Required Libraries\n",
    "\n",
    "For this lesson you will also need to install the following libraries:\n",
    "\n",
    "```bash\n",
    "pip install google-generativeai pandas\n",
    "```\n",
    "\n",
    "`google-generativeai` is the library we will be using to interact with the Gemini API.\n",
    "\n",
    "### 6. Import Packages\n",
    "\n",
    "Next, import these packages into your environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Set Up API Key\n",
    "\n",
    "You will need to set up your API key using your already created environment variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['API_KEY'] = api_key\n",
    "genai.configure(api_key=os.environ['API_KEY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Prompt Process Under the Hood</ins>\n",
    "\n",
    "Before we begin digging into prompt engineering, let's familiarize ourselves on a high level with what happens under the hood when we send a prompt. This is definitely 'above our paygrade' and not what we will be focusing on, but it is good to be aware of. Take a look at this link which describes [The Process of A Prompt](https://github.com/jdrichards-pursuit/prompt-process-explained).\n",
    "\n",
    "### Parts of a Prompt\n",
    "\n",
    "When creating a prompt using the Gemini API, there are three main parts to consider:\n",
    "\n",
    "1. **Model**: The model you are using to generate the response. In our case, we are using the `gemini-1.5-flash` model.\n",
    "2. **Parameters**: Parameters are additional settings or options that you can send to the model to guide the response. We will cover these in more detail later in the lesson.\n",
    "3. **Prompt**: A prompt is the input or instruction given to an AI model to elicit a specific response or output. It's the text that guides the AI in understanding what kind of information or task you're requesting.\n",
    "\n",
    "\n",
    "### Model\n",
    "For this lesson, we will be using the `gemini-1.5-flash` model because it is free and '...is a fast and versatile multimodal model for scaling across diverse tasks.' to quote the [Gemini API Documentation](https://ai.google.dev/gemini-api/docs/models/gemini#gemini-1.5-flash).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "When we send a prompt to the model, we can also send parameters to the model. These parameters are used to guide the model's response. In Gemini API, there are several parameters we can send to the model, but for now we will focus on the following:\n",
    "\n",
    "1. `temperature`: This parameter controls the randomness of the model's response. A temperature of 0 is deterministic, meaning the model will always return the same response for a given prompt. A temperature between 0 and 1 will make the response more random. \n",
    "2. `max_output_tokens`: This parameter controls the maximum number of tokens in the model's response.\n",
    "3. `num_return_sequences`: This parameter controls the number of alternative completions to generate.\n",
    "\n",
    "There are many more parameters, but we will not focus on those for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Temperature\n",
    "\n",
    "- This parameter controls the randomness of the generated text.\n",
    "\n",
    "- Think of it like adjusting the \"creativity\" or \"originality\" of the generated text:\n",
    "\n",
    "    - A low temperature setting is ideal for:\n",
    "\n",
    "        - Answering factual questions (e.g., \"What is the capital of France?\")\n",
    "        - Generating technical documentation or instruction manuals\n",
    "        - Providing definitions or explanations of complex terms\n",
    "        - Summarizing scientific papers or reports\n",
    "\n",
    "\n",
    "    - A high temperature setting is beneficial for:\n",
    "\n",
    "        - Generating story ideas or plot twists\n",
    "        - Coming up with unique marketing slogans or taglines\n",
    "        - Brainstorming solutions to open-ended problems\n",
    "\n",
    "\n",
    "- By default, the API uses a temperature of 0.5, which is a good balance between creativity and coherence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Max Output Tokens\n",
    "\n",
    "- This parameter sets the maximum number of tokens in the generated text.\n",
    "- A token is the smallest unit of text that the model can generate.\n",
    "- If you set max_output_tokens to 20, the API will generate text that's around 20 tokens long. \n",
    "- **Note:** Tokens are not the same as characters or words. They can be a word, a phrase, a sentence, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Num Return Sequences\n",
    "\n",
    "- This parameter sets the number of alternative completions to generate.\n",
    "- If you set num_return_sequences to 3, the API will generate 3 different completions for the same prompt.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets create a function, `get_completion`, that will submit a prompt to the Gemini API and return the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gemini-1.5-flash\", **kwargs):\n",
    "    model = genai.GenerativeModel(model)\n",
    "    \n",
    "    # Create a generation_config dictionary with default values\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.8,\n",
    "        \"max_output_tokens\": 200\n",
    "    }\n",
    "    \n",
    "    # Update generation_config with any provided kwargs\n",
    "    generation_config.update(kwargs)\n",
    "    \n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Walkthrough of the Code\n",
    "\n",
    "1. We first create a function called `get_completion` that takes in a prompt and any number of keyword arguments called `kwargs`.\n",
    "    - `**kwargs` allows us to pass in any number of keyword arguments to the function.\n",
    "    - the double asterisk is used to unpack the keyword arguments into a dictionary. In JavaScript, this would be `{...args}`.\n",
    "\n",
    "2. We then create a `generation_config` dictionary with default values for the parameters we want to default to.\n",
    "\n",
    "3. We then update the `generation_config` dictionary with any provided keyword arguments. This allows us to override the default values when we call the function.\n",
    "\n",
    "4. We then generate the response from the model using the `generate_content` method on the model dictionary.\n",
    "\n",
    "5. Finally, we return the response.\n",
    "\n",
    "\n",
    "\n",
    "#### Let's set a prompt and test out our function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Tell me about wines from Bordeaux.\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt,\n",
    "    temperature=0.9,\n",
    "    max_output_tokens=1000\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <ins>Prompt Engineering Techniques</ins>\n",
    "\n",
    "Prompt engineering is a crucial skill for effectively leveraging AI language models like Gemini Api, ChatGPT, Claude, etc. It involves crafting inputs that guide the AI to produce desired outputs. Mastering these techniques allows users to get more accurate, relevant, and useful responses from AI systems.\n",
    "\n",
    "Key prompt engineering techniques include but are not limited to:\n",
    "\n",
    "1. Formulating Effective Questions\n",
    "2. Providing Relevant Context\n",
    "3. Specifying Constraints in Your Queries\n",
    "4. Specifying Output Format\n",
    "5. Using Few Shot Examples\n",
    "6. Partial Inputs\n",
    "7. System Instructions\n",
    "\n",
    "\n",
    "These techniques help improve the AI's reasoning capabilities, enable more structured outputs, and enhance overall interaction quality with language models.\n",
    "\n",
    "### 1. Formulating Effective Questions\n",
    "\n",
    "Whether you're analyzing data or seeking general information, asking clear and specific questions is crucial. Let's explore how to frame your queries effectively in both data-related and general contexts.\n",
    "\n",
    "#### Clear vs. Vague Instructions\n",
    "\n",
    "#### Data Example:\n",
    "```python\n",
    "# Good: Clear and specific question\n",
    "\"\"\"\n",
    "What is the average sale price of houses with more than 3 bedrooms \n",
    "in the 'Seattle' area from our housing dataset?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Vague and ambiguous question\n",
    "\"\"\"\n",
    "What can you tell me about the houses in the dataset?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "```python\n",
    "# Good: Clear and specific question\n",
    "\"\"\"\n",
    "What are the three main causes of deforestation in the Amazon rainforest \n",
    "over the past decade?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Vague and ambiguous question\n",
    "\"\"\"\n",
    "Tell me about forests.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Discuss the difference between the clear and vague instructions listed above.\n",
    "\n",
    "### Practice (10 minutes)\n",
    "\n",
    "Imagine you're asking someone to explain the concept of climate change.\n",
    "\n",
    "1. Write a vague instruction for explaining climate change.\n",
    "2. Rewrite the instruction to make it clear and specific. Consider asking for a few key points to be covered, such as but not limited to:\n",
    "\n",
    "    - Definition of climate change\n",
    "    - Main causes (e.g., greenhouse gases, human activities)\n",
    "    - Observable effects (e.g., rising temperatures, extreme weather events)\n",
    "    Potential future impacts\n",
    "    - Possible solutions or mitigation strategies\n",
    "    - Request the use of simple language suitable for a general audience\n",
    "    - Ask for one or two specific examples or statistics to illustrate key points\n",
    "\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your vague instruction:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your clear and specific instruction:\n",
    "\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Providing Relevant Context\n",
    "\n",
    "Providing relevant context is crucial for guiding the model to produce accurate and relevant responses. This can be achieved by including relevant information about the dataset or the task at hand.\n",
    "\n",
    "##### Data Example:\n",
    "```python\n",
    "# Good: Includes relevant context\n",
    "\"\"\"\n",
    "Our dataset 'sales.csv' contains columns for 'price', 'bedrooms', and 'location'.\n",
    "Can you show me how to calculate the median price for each bedroom category?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Lacks necessary context\n",
    "\"\"\"\n",
    "Calculate the median prices.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Non-Data Example:\n",
    "```python\n",
    "# Good: Includes relevant context\n",
    "\"\"\"\n",
    "In the context of object-oriented programming in Python, \n",
    "can you explain the concept of inheritance with a simple example?\n",
    "\"\"\"\n",
    "\n",
    "# Bad: Lacks necessary context\n",
    "\"\"\"\n",
    "What is inheritance?\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Discuss the difference between the two prompts above. Why is one better than the other?\n",
    "\n",
    "\n",
    "### Practice (10 minutes)\n",
    "\n",
    "Imagine you're asking for advice on how to care for a specific type of houseplant.\n",
    "\n",
    "1. Write a prompt without providing any context.\n",
    "2. Then, rewrite the prompt to include relevant context.\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "Relevant context for houseplant care could include:\n",
    "- Plant species or variety\n",
    "- Plant size and age\n",
    "- Light conditions\n",
    "- Location in the home\n",
    "- Temperature and humidity levels\n",
    "- Current plant health\n",
    "- Watering habits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your prompt without context:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your prompt with context:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Specifying Constraints in Your Queries\n",
    "\n",
    "When working with data or seeking information, it's important to specify any constraints or limitations in your request. This helps ensure you get precisely the information you need in the format you want.\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Good: Specifies constraints clearly\n",
    "\"\"\"\n",
    "From our 'employee_data.csv', analyze the salary distribution for employees \n",
    "who joined in the last 2 years. Provide the 25th, 50th, and 75th percentiles, \n",
    "and limit your response to a maximum of 4 bullet points.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Bad: Lacks specific constraints\n",
    "\"\"\"\n",
    "Analyze the salary distribution from the employee data.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Good: Specifies constraints clearly\n",
    "\"\"\"\n",
    "Explain the concept of recursion in programming. Use exactly 3 sentences \n",
    "and provide a simple example that doesn't involve calculating factorials \n",
    "or Fibonacci numbers.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Bad: Lacks specific constraints\n",
    "\"\"\"\n",
    "Explain recursion in programming.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Remember: By specifying constraints such as time periods, specific metrics, response format, or content limitations, you can ensure that the response meets your needs exactly. This is crucial whether you're analyzing data from a CSV file or seeking general information on a topic.\n",
    "\n",
    "### Practice (10 minutes)\n",
    "\n",
    "Imagine you're asking for recommendations for a book to read.\n",
    "\n",
    "1. Write a prompt without specifying any constraints.\n",
    "2. Rewrite the prompt to include specific constraints. Constraints could include but not limited to:\n",
    "\n",
    "    - Genre (e.g., science fiction, mystery, historical fiction)\n",
    "    - Publication date (e.g., published in the last 5 years)\n",
    "    - Awards or recognition (e.g., has won at least one major literary award)\n",
    "    - Themes or topics (e.g., features themes of artificial intelligence or space exploration)\n",
    "    - Target audience (e.g., suitable for young adult readers)\n",
    "    - Length (e.g., under 400 pages long)\n",
    "    - Format of the recommendation (e.g., provide title, author, and a brief description)\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses.\n",
    "\n",
    "Consider including constraints such as:\n",
    "\n",
    "- Genre (e.g., science fiction, mystery, historical fiction)\n",
    "- Publication date (e.g., published in the last 5 years)\n",
    "- Awards or recognition (e.g., has won at least one major literary award)\n",
    "- Themes or topics (e.g., features themes of artificial intelligence or space exploration)\n",
    "- Target audience (e.g., suitable for young adult readers)\n",
    "- Length (e.g., under 400 pages long)\n",
    "- Format of the recommendation (e.g., provide title, author, and a brief description)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Specifying Output Format\n",
    "\n",
    "When working with data or seeking information, you can guide the model to provide responses in a specific format. This is particularly useful when you need structured outputs for further processing or analysis. This structured output can be in the form of a JSON, a table, a list, etc. Your example for this structure can either be a partial example or a full example.\n",
    "\n",
    "##### Data Example:\n",
    "\n",
    "#### Prompt without format specification:\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Analyze the top 3 selling products from our 'annual_sales.csv' file.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```\n",
    "Based on the analysis of the 'annual_sales.csv' file, the top 3 selling products are:\n",
    "\n",
    "1. Smartphone X: This product led in units sold with 50,000 units, generating a revenue of $25,000,000.\n",
    "\n",
    "2. Laptop Pro: While selling fewer units (30,000) than the Smartphone X, it generated the highest revenue at $45,000,000 due to its higher price point.\n",
    "\n",
    "3. Wireless Earbuds: This product showed strong unit sales at 100,000, but had a lower revenue of $15,000,000, indicating a lower price point.\n",
    "\n",
    "These top products demonstrate a mix of high-volume and high-value items, with smartphones leading in units sold and laptops in revenue generation.\n",
    "```\n",
    "\n",
    "To ensure a specific JSON format, you can provide the beginning of the JSON structure:\n",
    "\n",
    "#### Prompt with format specification (using partial JSON structure):\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze the top 3 selling products from our 'annual_sales.csv' file. \n",
    "Provide the output in the following JSON format:\n",
    "\n",
    "{\n",
    "  \"top_products\": [\n",
    "    {\n",
    "      \"rank\": 1,\n",
    "      \"name\": \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"top_products\": [\n",
    "    {\n",
    "      \"rank\": 1,\n",
    "      \"name\": \"Smartphone X\",\n",
    "      \"units_sold\": 50000,\n",
    "      \"revenue\": 25000000\n",
    "    },\n",
    "    {\n",
    "      \"rank\": 2,\n",
    "      \"name\": \"Laptop Pro\",\n",
    "      \"units_sold\": 30000,\n",
    "      \"revenue\": 45000000\n",
    "    },\n",
    "    {\n",
    "      \"rank\": 3,\n",
    "      \"name\": \"Wireless Earbuds\",\n",
    "      \"units_sold\": 100000,\n",
    "      \"revenue\": 15000000\n",
    "    }\n",
    "  ],\n",
    "  \"analysis\": \"The top 3 products demonstrate a balance between high-volume and high-value items. Smartphone X leads in units sold, while Laptop Pro generates the highest revenue. Wireless Earbuds show strong unit sales but lower per-unit revenue.\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Non-Data Example:\n",
    "\n",
    "#### Prompt without format specification:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Describe the key features of Python programming language.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```\n",
    "Python is a popular programming language known for several key features:\n",
    "\n",
    "1. Easy to learn and read syntax: Python uses indentation and simple keywords, making it accessible for beginners and easy to read for all developers.\n",
    "\n",
    "2. Interpreted language: Python code is executed line by line, allowing for rapid development and debugging.\n",
    "\n",
    "3. Dynamically typed: Variables in Python can change types, providing flexibility in programming.\n",
    "\n",
    "4. Object-oriented programming support: Python supports OOP concepts like classes, inheritance, and encapsulation.\n",
    "\n",
    "5. Extensive standard library: Python comes with a large library of pre-built modules, reducing the need for external dependencies.\n",
    "\n",
    "6. Cross-platform compatibility: Python programs can run on various operating systems with minimal modifications.\n",
    "\n",
    "Python is widely used in web development, data analysis, artificial intelligence, machine learning, scientific computing, and automation tasks. The latest stable version as of May 2021 is 3.9.5.\n",
    "```\n",
    "\n",
    "To ensure a specific JSON format, you can provide the beginning of the JSON structure:\n",
    "\n",
    "#### Prompt with format specification (using partial JSON structure):\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Describe the key features of Python programming language. \n",
    "Provide the output in the following JSON format:\n",
    "\n",
    "{\n",
    "  \"language\": \"Python\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Possible Response:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"language\": \"Python\",\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"name\": \"Easy to learn and read syntax\",\n",
    "      \"description\": \"Python uses indentation and simple keywords, making it accessible for beginners and easy to read for all developers.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Interpreted language\",\n",
    "      \"description\": \"Python code is executed line by line, allowing for rapid development and debugging.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Dynamically typed\",\n",
    "      \"description\": \"Variables in Python can change types, providing flexibility in programming.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Extensive standard library\",\n",
    "      \"description\": \"Python comes with a large library of pre-built modules, reducing the need for external dependencies.\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"Cross-platform compatibility\",\n",
    "      \"description\": \"Python programs can run on various operating systems with minimal modifications.\"\n",
    "    }\n",
    "  ],\n",
    "  \"version\": \"3.9.5\",\n",
    "  \"popular_applications\": [\"Web development\", \"Data analysis\", \"AI and machine learning\", \"Scientific computing\"]\n",
    "}\n",
    "```\n",
    "\n",
    "Remember: By providing a structure for the desired output format, you can guide the model to generate responses in a consistent and easily parseable format, whether you're analyzing data from a CSV file or seeking information on programming concepts.\n",
    "\n",
    "### Practice (10 minutes)\n",
    "\n",
    "Imagine you're asking for information about a historical event.\n",
    "\n",
    "1. Write a prompt without specifying any output format.\n",
    "2. Rewrite the prompt to include a specific output format. Possible formats could include but not limited to:\n",
    "\n",
    "- Bulleted list\n",
    "- JSON\n",
    "- Timeline\n",
    "- Table\n",
    "- Pros and cons list\n",
    "- Q&A format\n",
    "- Step-by-step guide\n",
    "- Comparison chart\n",
    "- Brief paragraph summary\n",
    "\n",
    "Historical events could include:\n",
    "\n",
    "- World War II\n",
    "- The Great Fire of London\n",
    "- The French Revolution\n",
    "- The American Revolution  \n",
    "\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your prompt without specifying output format:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your prompt with specifying output format:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Including Few-Shot Examples in Your Queries\n",
    "\n",
    "When working with data or seeking information, providing examples in your prompt can help guide the model to produce more accurate and appropriately formatted responses. This technique is called \"few-shot learning\" and can be applied to both data analysis tasks and general inquiries.\n",
    "\n",
    "#### Definitions:\n",
    "\n",
    "- **Zero-shot prompt**: A prompt that provides no examples, relying solely on instructions.\n",
    "- **One-shot prompt**: A prompt that includes a single example to guide the model's response.\n",
    "- **Few-shot prompt**: A prompt that contains multiple examples to demonstrate the desired pattern or format.\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "##### Zero-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze the sales data from our 'quarterly_sales.csv' file and provide a summary \n",
    "of the top-performing products.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Few-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here are two examples of how to analyze and summarize sales data:\n",
    "\n",
    "Example 1:\n",
    "Input: Analyze Q1 sales for electronic products\n",
    "Output:\n",
    "1. Top product: Smartphones (Revenue: $1.2M, Units sold: 5000)\n",
    "2. Fastest growing: Wireless earbuds (300% growth from last quarter)\n",
    "3. Underperformer: Tablets (20% decline in sales)\n",
    "\n",
    "Example 2:\n",
    "Input: Summarize Q2 sales for home appliances\n",
    "Output:\n",
    "1. Best seller: Robot vacuums (Revenue: $800K, Units sold: 2000)\n",
    "2. Surprise hit: Smart thermostats (150% increase in demand)\n",
    "3. Needs attention: Microwave ovens (10% drop in market share)\n",
    "\n",
    "Now, using the same format, analyze the sales data from our 'quarterly_sales.csv' \n",
    "file and provide a summary of the top-performing products for Q3.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "##### One-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here's an example of how to explain a programming concept concisely:\n",
    "\n",
    "Concept: List comprehension in Python\n",
    "Explanation: A compact way to create lists based on existing lists or iterables, \n",
    "combining a for loop and a conditional statement in a single line of code.\n",
    "\n",
    "Now, using the same concise format, explain the concept of 'decorator' in Python.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "##### Few-shot prompt:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Here are two examples of explaining programming concepts:\n",
    "\n",
    "Concept: List comprehension in Python\n",
    "Explanation: A compact way to create lists based on existing lists or iterables, \n",
    "combining a for loop and a conditional statement in a single line of code.\n",
    "\n",
    "Concept: Lambda functions in Python\n",
    "Explanation: Anonymous, inline functions defined using the 'lambda' keyword, \n",
    "typically used for simple operations and as arguments to higher-order functions.\n",
    "\n",
    "Now, using the same concise format, explain the following two concepts:\n",
    "1. Decorator in Python\n",
    "2. Generator expression in Python\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "Remember: Including examples in your prompts can significantly improve the relevance and format of the responses, whether you're analyzing data from a CSV file or seeking explanations for programming concepts.\n",
    "\n",
    "### Practice (15 minutes)\n",
    "\n",
    "Your goal is to create prompts that will instruct a language model to convert informal text messages into more formal, professional language.\n",
    "\n",
    "1. Write a zero-shot prompt for this task without providing any examples.\n",
    "2. Write a few-shot prompt that includes at least two examples to guide the model's response. Possible examples could include but not limited to:\n",
    "\n",
    "- Informal to Formal\n",
    "- Short to Long\n",
    "- Casual to Professional\n",
    "- Friendly to Formal\n",
    "- Short to Long\n",
    "\n",
    "3. Show the class what you wrote for both prompts and explain the differences in the two model responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your zero-shot prompt:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "# Your few-shot prompt:\n",
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Partial Inputs: Let the Model Complete the Input\n",
    "Generative language models can function as sophisticated autocomplete systems. \n",
    "\n",
    "When given incomplete information, these models can generate the remaining content or what they interpret as a logical continuation. The model takes into account any provided examples or context when generating its response.\n",
    "\n",
    "Below are two examples demonstrating how to use partial inputs with the model: \n",
    "one for data analysis and another for creative writing.\n",
    "\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Complete the analysis of the following stock market data:\n",
    "\n",
    "AAPL (Apple Inc.):\n",
    "- Opening price: $150.25\n",
    "- Closing price: $152.75\n",
    "- Volume: 82.5M shares\n",
    "\n",
    "GOOGL (Alphabet Inc.):\n",
    "- Opening price: $2,750.50\n",
    "- Closing price: $2,778.25\n",
    "- Volume: 1.2M shares\n",
    "\n",
    "Analysis:\n",
    "1. Apple's stock price increased by\n",
    "\"\"\"\n",
    "```\n",
    "### Possible Response:\n",
    "\n",
    "```\n",
    "Apple Inc. (AAPL):\n",
    "\n",
    "1.Apple's stock price increased by $2.50. This is calculated by subtracting the opening price from the closing price: $152.75 - $150.25 = $2.50.\n",
    "\n",
    "2. Apple's trading volume was 82.5 million shares.\n",
    "\n",
    "Alphabet Inc. (GOOGL):\n",
    "\n",
    "1.  Alphabet's stock price increased by $27.75. This is calculated by subtracting the opening price from the closing price: $2,778.25 - $2,750.50 = $27.75.\n",
    "\n",
    "2. Alphabet's trading volume was 1.2 million shares.\n",
    "```\n",
    "\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "For the given model return a python dictionary with the fields coffee, tea, muffin, biscotti, with the value being the quantity. Make sure you include to the proper field even if the field word input is plural.\n",
    "\n",
    "Order: 2 coffees, 1 tea, 3 muffins, 2 biscotti\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "### Possible Response:\n",
    "\n",
    "```python\n",
    "{\n",
    "    \"coffee\": 2,\n",
    "    \"tea\": 1,\n",
    "    \"muffin\": 3,\n",
    "    \"biscotti\": 2\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "### Practice (10 minutes)\n",
    "\n",
    "Create a partial input prompt for a creative writing scenario. This exercise will help you understand how language models can complete and expand on given contexts.\n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Choose a creative writing scenario (5 minutes):\n",
    "   Select one of the following or create your own:\n",
    "   - The beginning of a short story\n",
    "   - The opening lines of a poem\n",
    "   - The start of a motivational speech\n",
    "   - The introduction to a fictional character\n",
    "\n",
    "2. Write your partial input (5 minutes):\n",
    "   - Write 2-3 sentences to set up your chosen scenario\n",
    "   - Add 1 more sentence to start the continuation point\n",
    "   - Ensure your partial input provides clear context but leaves room for creative completion\n",
    "\n",
    "3. Show your partial input to the class and explain how it sets up the scenario as well as the output you received from the model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(response) # this is the response from the model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. System Instructions: Shaping AI Behavior\n",
    "\n",
    "System instructions, also known as system prompts, are high-level directives that set the overall behavior and role of the AI model. They are powerful tools for defining how an AI model should behave and respond. These instructions can be used to continuously shape the behavior of the AI model without repeating the same instructions over and over again.\n",
    "\n",
    "#### Data Example:\n",
    "\n",
    "```python\n",
    "# Bad System Instructions:\n",
    "system_instructions = \"\"\"\n",
    "You're a data person. Look at sales numbers and tell me what's going on.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "# Good System Instructions:\n",
    "system_instructions = \"\"\"\n",
    "You are a data analysis expert specializing in sales trends. Your role is to analyze \n",
    "sales data and provide insights. Follow these guidelines:\n",
    "\n",
    "1. Always use precise numerical values when reporting figures.\n",
    "2. Provide a summary of overall trends before diving into specifics.\n",
    "3. Highlight any anomalies or unexpected patterns in the data.\n",
    "4. When comparing periods, use percentage changes for clarity.\n",
    "5. Suggest possible reasons for significant changes in sales patterns.\n",
    "6. Always specify the time period for which the analysis is being conducted.\n",
    "7. If data is missing or seems inconsistent, flag it in your analysis.\n",
    "8. Provide actionable insights based on the data whenever possible.\n",
    "9. Use appropriate data visualization techniques when helpful (describe them in words).\n",
    "10. If asked about future predictions, clearly state that these are projections based on current data.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### User Prompt:\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "Analyze the quarterly sales data for our electronics department over the past year. \n",
    "Focus on identifying our best-selling products and any seasonal trends.\n",
    "\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "#### Non-Data Example:\n",
    "\n",
    "```python\n",
    "# Bad System Instructions:\n",
    "system_instructions = \"\"\"\n",
    "You know about writing. Help people write better.\n",
    "\"\"\" \n",
    "```\n",
    "\n",
    "```python\n",
    "# Good System Instructions:\n",
    "system_instructions = \"\"\"\n",
    "You are an expert in creative writing techniques. Your role is to guide aspiring \n",
    "writers in improving their craft. Adhere to these guidelines:\n",
    "\n",
    "1. Provide constructive feedback that is both encouraging and honest.\n",
    "2. Offer specific examples to illustrate writing principles.\n",
    "3. Tailor advice to the genre or style the writer is working in.\n",
    "4. Encourage experimentation with different techniques and styles.\n",
    "5. When critiquing, always start with positive aspects before suggesting improvements.\n",
    "6. Provide exercises or prompts to help writers practice specific skills.\n",
    "7. Explain the reasoning behind your suggestions.\n",
    "8. Respect the writer's unique voice and style while offering improvement ideas.\n",
    "9. Recommend relevant books or resources for further learning when appropriate.\n",
    "10. If asked about publishing or the business side of writing, provide current, \n",
    "    factual information or direct to reliable sources.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "#### User Prompt:\n",
    "```python\n",
    "prompt = \"\"\"\n",
    "I'm working on a short story and I'm struggling with dialogue. Can you give me some tips on how to make my characters' conversations sound more natural?\n",
    "\"\"\"\n",
    "```\n",
    "Remember: System instructions set the overall context and behavior for the AI model, while user prompts are the specific queries or tasks within that context. This separation allows for consistent behavior across multiple interactions without repeating the same instructions.\n",
    "\n",
    "### Practice (20 minutes)\n",
    "\n",
    "Your task is to create system instructions for an AI language model that will act as a basic calculator assistant.\n",
    "\n",
    "1. Write a set of system instructions that define the AI's role as a calculator. Keep it simple and focused on basic arithmetic operations (addition, subtraction, multiplication, division).\n",
    "\n",
    "2. Create two example user prompts that someone might ask this calculator assistant. For example:\n",
    "   - A simple arithmetic question\n",
    "   - A request to explain a basic math concept\n",
    "When creating your system instructions for the basic calculator assistant, you might want to think about:\n",
    "\n",
    "- How to handle decimal places in calculations\n",
    "- Whether to show step-by-step solutions\n",
    "- How to respond to requests for operations beyond basic arithmetic\n",
    "- Dealing with unclear or ambiguous requests\n",
    "- Explaining mathematical concepts in addition to performing calculations\n",
    "- Using consistent mathematical notation\n",
    "- Handling potential division by zero errors\n",
    "- Whether to accept and understand various input formats (e.g., fractions, percentages)\n",
    "- How to respond if asked about the history or cultural context of mathematical concepts\n",
    "- Balancing brevity with clarity in responses\n",
    "\n",
    "Remember, you don't need to address all of these points in your instructions. Choose the ones you think are most important for a basic calculator assistant.\n",
    "\n",
    "3. Share your system instructions and example user prompts with the class. Briefly explain how your instructions shape the AI's behavior.\n",
    "\n",
    "Tips:\n",
    "- Keep the system instructions concise, aiming for 5-7 clear guidelines.\n",
    "- Focus on accuracy and clarity in mathematical operations.\n",
    "- Consider how to handle potential errors or unclear requests.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt,system_instruction=None, model=\"gemini-1.5-flash\", **kwargs):\n",
    "    model = genai.GenerativeModel(model)\n",
    "    \n",
    "    if system_instruction:\n",
    "        prompt = f\"{system_instruction}\\n\\n{prompt}\"\n",
    "    \n",
    "    # Create a generation_config dictionary with default values\n",
    "    generation_config = {\n",
    "        \"temperature\": 0.7,\n",
    "        \"min_length\": 20,\n",
    "        \"max_length\": 200,\n",
    "        \"max_output_tokens\": 2020,\n",
    "    }\n",
    "    \n",
    "    # Update generation_config with any provided kwargs\n",
    "    generation_config.update(kwargs)\n",
    "    \n",
    "    response = model.generate_content(prompt, generation_config=generation_config)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment and uncomment your prompts one at a time to see the difference\n",
    "# Your basic system instruction:\n",
    "system_instruction = \"\"\"\n",
    "\"\"\"\n",
    "# Your more effective and specialized system instruction:\n",
    "system_instruction = \"\"\"\n",
    "\"\"\"                         \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
